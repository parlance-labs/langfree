# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_experimental.ipynb.

# %% auto 0
__all__ = ['ChatRecord', 'ChatRecordSet']

# %% ../nbs/03_experimental.ipynb 2
from typing import List, Iterable, Union
from collections import Counter
from pathlib import Path
import pickle

import pandas as pd
from pydantic import BaseModel
import langsmith
from fastcore.foundation import first, L
from fastcore.test import test_eq
from .runs import (get_runs_by_commit, get_output, get_input, 
                           get_params, get_functions,
                          get_feedback, take)
from .transform import RunData
from langsmith import Client

# %% ../nbs/03_experimental.ipynb 4
class ChatRecord(BaseModel):
    "A parsed run from LangSmith, focused on the `ChatOpenAI` run type."
    child_run_id:str
    parent_run_id:str
    child_run:RunData
    url: str
    total_tokens:Union[int, None]
    prompt_tokens:Union[int, None]
    completion_tokens:Union[int, None]
    feedback: Union[List,None] = None
    feedback_keys: Union[List,None] = None
    tags: Union[List,None] = []
    start_dt: Union[str, None] = None
    parent_url: Union[str,None] = None
    parent_id: Union[str,None] = None
    function_defs: Union[List,None] = None
    param_model_name: Union[str,None]= None
    param_n: Union[int, None] = None
    param_top_p: Union[int, None] = None
    param_temp: Union[int, None] = None
    param_presence_penalty: Union[int, None] = None
    param_freq_penalty: Union[int, None] = None
    warnings: List[str] = []

    @property
    def flat_input(self): return self.child_run.flat_input
    
    @property
    def flat_output(self): return self.child_run.flat_output

    @classmethod
    def from_run_id(cls, 
                    run_id:str # the run id to fetch and parse.
                   ):
        "Collect information About A Run into a `ChatRecord`."
        client = Client()
        return cls.from_run(client.read_run(run_id=run_id))
    
    @classmethod
    def from_run(cls, 
                 run:langsmith.schemas.Run # the run object to parse.
                ):
        "Collect information About A Run into a `ChatRecord`."
        client = Client()
        warnings = []
        if run.execution_order != 1: # this is a child run, get the parent
            run = client.read_run(run.parent_run_id)
            
        _cruns = client.read_run(run_id=run.id, load_child_runs=True).child_runs
        crun = None
        if _cruns:
            if _cruns[-1].name != 'ChatOpenAI': 
                warnings.append('Last Step Not ChatOpenAI')
            crun = [c for c in _cruns if c.name == 'ChatOpenAI'][-1]
    
        if crun:
            _input, _output = get_input(crun), get_output(crun)      
            if 'Agent stopped due to max iterations' in _input: warnings.append('Max Iterations')
            if _output.strip() == '': warnings.append('No Output')
            
            params = get_params(crun)
            _feedback = get_feedback(run) # you must get feedback from the root
            
            return cls(child_run_id=str(crun.id),
                       parent_run_id=str(run.id),
                       child_run=RunData.from_run_id(str(crun.id)),
                       url=crun.url,
                       total_tokens=crun.total_tokens,
                       prompt_tokens=crun.prompt_tokens,
                       completion_tokens=crun.completion_tokens,
                       feedback=_feedback, 
                       feedback_keys=list(L(_feedback).attrgot('key').filter()),
                       tags=run.tags,
                       start_dt=run.start_time.strftime('%m/%d/%Y'),
                       parent_url=run.url if run else None,
                       parent_id=str(run.id) if run else None,
                       function_defs=get_functions(crun),
                       warnings=warnings,
                       **params)

# %% ../nbs/03_experimental.ipynb 13
class ChatRecordSet(BaseModel):
    "A List of `ChatRecord`."
    records: List[ChatRecord]
    
    @classmethod
    def from_commit(cls, commit_id:str):
        "Create a `LLMDataset` from a commit id"
        _runs = get_runs_by_commit(commit_id=commit_id)
        return cls.from_runs(_runs)
    
    @classmethod
    def from_runs(cls, runs:List[langsmith.schemas.Run]):
        "Load LLMDataset from runs."
        _records=[ChatRecord.from_run(r) for r in runs]
        records=[r for r in _records if _records]
        return cls(records=records)
    
    def __len__(self): return len(self.records)
    
    def save(self, path:str):
        "Save data to disk."
        dest_path = Path(path)
        if not dest_path.parent.exists(): dest_path.parent.mkdir(exist_ok=True)
        with open(dest_path, 'wb') as f:
            pickle.dump(self, f)
            return dest_path
        
    def __iter__(self): 
        for r in self.records: 
            yield r
    
    @classmethod
    def load(cls, path:str):
        "Load data from disk."
        src_path = Path(path)
        with open(src_path, 'rb') as f:
            obj = pickle.load(f)
            if isinstance(obj, cls):
                return obj
            else:
                raise TypeError(f"The loaded object is not of type {cls.__name__}")
                
    def to_pandas(self):
        "Convert the `LLMDataset` to a pandas.DataFrame."
        records = L(self.records).map(lambda x: dict(
                                                     flat_input=x.flat_input,
                                                     flat_output=x.flat_output,
                                                     **dict(x)
                                                    )
                                     )                           
        return pd.DataFrame(records)
