{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runs\n",
    "\n",
    "> Get lang model runs from langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from datetime import date, timedelta, datetime\n",
    "from itertools import islice\n",
    "from typing import List, Iterable\n",
    "from pprint import pformat\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.load import load\n",
    "import langsmith\n",
    "from langsmith import Client\n",
    "from fastcore.foundation import L, first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@contextmanager\n",
    "def _temp_env_var(vars_dict):\n",
    "    \"Temporarily set environment variables (for testing)\"\n",
    "    original_values = {name: os.environ.get(name) for name in vars_dict.keys()}\n",
    "    \n",
    "    # Set temporary values\n",
    "    for name, value in vars_dict.items():\n",
    "        os.environ[name] = value\n",
    "        \n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        # Revert changes after block execution\n",
    "        for name, original_value in original_values.items():\n",
    "            if original_value is None:\n",
    "                del os.environ[name]\n",
    "            else:\n",
    "                os.environ[name] = original_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def check_api_key(nm=\"LANGCHAIN_HUB_API_KEY\"):\n",
    "    val = os.getenv(nm)\n",
    "    if not val: raise Exception(f\"You must set the environment variable {nm}\")\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "#|hide\n",
    "check_api_key(\"LANGCHAIN_API_KEY\")\n",
    "check_api_key(\"LANGCHAIN_ENDPOINT\")\n",
    "check_api_key(\"LANGSMITH_PROJECT_ID\")\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Runs\n",
    "\n",
    "### Background \n",
    "\n",
    "Langsmith offers a convenient [python client](https://github.com/langchain-ai/langsmith-sdk) for retrieving runs.  [The docs](https://docs.smith.langchain.com/tracing/use-cases/export-runs/local) go into further detail about the various options available.  Some useful patterns to know are:\n",
    "\n",
    "Getting a list of runs:\n",
    "\n",
    "```python\n",
    "from langsmith import Client\n",
    "client = Client()\n",
    "project_runs = client.list_runs(project_name=\"<your_project>\")\n",
    "```\n",
    "\n",
    "Getting a specific run:\n",
    "\n",
    "```python\n",
    "from langsmith import Client\n",
    "client = Client()\n",
    "run = client.client.read_run(\"<run_id>\")\n",
    "```\n",
    "\n",
    "Furthermore, there are various ways to filter and search runs which are described in [the documentation](https://docs.smith.langchain.com/tracing/use-cases/export-runs).  If these suit your needs, you may not need the utilities in this module.  This module offers opinionated wrappers around the Langsmith client that retrieve runs using common patterns we have seen.\n",
    "\n",
    "### Utilities\n",
    "\n",
    "The following functions help retrieve runs by a very specific kind of [tag](https://docs.smith.langchain.com/tracing/tracing-faq#how-do-i-add-tags-to-runs), as well as recent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def take(l:Iterable, n:int):\n",
    "    \"Take first n entries from a generator\"\n",
    "    return L(islice(l, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_runs_by_commit(commit_id:str=None, # The commit ID to filter by \n",
    "             proj_id:str=None, # Langsmith Project ID\n",
    "             only_success=True, # Only include runs that are successfull\n",
    "             run_type='chain', # The run type\n",
    "             start_dt:str=None, # The start date to filter by\n",
    "             end_dt:str=None    # the end date to filter by\n",
    "            ):\n",
    "    \"Get all runs tagged with a particular commit id (the short version of the SHA) in LangSmith.\"\n",
    "    \n",
    "    success_query='eq(status, \"success\")' if only_success else ''\n",
    "    commit_query = f'has(tags, \"commit:{commit_id}\")' if commit_id else ''\n",
    "    proj_id = check_api_key(\"LANGSMITH_PROJECT_ID\") if not proj_id else proj_id\n",
    "    time_query=''\n",
    "    \n",
    "    if start_dt:\n",
    "        time_query=f'gte(start_time, \"{start_dt}\")'\n",
    "        if end_dt:\n",
    "            time_query = f'{time_query}, lte(start_time, \"{end_dt}\")'\n",
    "    \n",
    "    queries = ', '.join(L([success_query, commit_query, time_query]).filter())\n",
    "    query_string = None if not queries else f'and({queries})'\n",
    "    if query_string: print(f'Fetching runs with this filter: {query_string}')\n",
    "        \n",
    "    runs = client.list_runs(\n",
    "        filter=query_string,\n",
    "        project_id=proj_id,\n",
    "        execution_order=1, # this gets the root runs\n",
    "        error=False,\n",
    "        run_type=run_type,\n",
    "    )\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind `get_runs_by_commit` is to quickly retrieve runs that are being logged to langsmith in CI, for example if you are running offline tests automatically against your language models. For example, let's get runs with the tag `commit:4f59dcec` in LangSmith (this is specific to my project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching runs with this filter: and(eq(status, \"success\"), has(tags, \"commit:4f59dcec\"))\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "_runs = take(get_runs_by_commit('4f59dcec'), 5)\n",
    "assert set(_runs.map(lambda x: x.tags[0])) == {'commit:4f59dcec'} # check that all runs have this tag\n",
    "assert set(_runs.map(lambda x: x.status)) == {'success'} # check that these runs are successfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/4/2023\"), lte(start_time, \"10/5/2023\"))\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "_runs = L(get_runs_by_commit(start_dt='10/4/2023', end_dt='10/5/2023'))\n",
    "n_runs = len(_runs)\n",
    "assert n_runs > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_last_child(runs: List[langsmith.schemas.Run]):\n",
    "    \"Get the child runs for a list of runs.\"\n",
    "    return [client.read_run(r.child_run_ids[-1]) for r in runs if r.child_run_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LangSmith, the last child is often useful to view the final call to the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_child_runs = get_last_child(take(_runs, 3))\n",
    "assert _child_runs[0].child_run_ids is None # the child doesn't have other children\n",
    "assert _child_runs[0].execution_order != 1  # the child shouldn't be executed first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_recent_runs(start_dt=None, end_dt=None, last_n_days=2):\n",
    "    \"Get recent runs from Langsmith.  If `start_dt` is None gets the `last_n_days`.\"\n",
    "    if start_dt is None:\n",
    "        _runs = client.list_runs(project_id=check_api_key(\"LANGSMITH_PROJECT_ID\"), limit=1)\n",
    "        latest_run_dt = first(_runs).start_time\n",
    "        start_dt_obj = latest_run_dt - timedelta(days=last_n_days)\n",
    "    else:\n",
    "        start_dt_obj = datetime.strptime(start_dt, '%m/%d/%Y')\n",
    "        \n",
    "    if end_dt is None:\n",
    "        if start_dt is None:\n",
    "            end_dt_obj = start_dt_obj + timedelta(days=last_n_days+1) # their logic is off lte is really lt\n",
    "        else:\n",
    "            end_dt_obj = datetime.strptime(start_dt, '%m/%d/%Y') + timedelta(days=last_n_days+1) # their logic is off lte is really lt   \n",
    "    else:\n",
    "        if start_dt is None:\n",
    "            raise ValueError(\"end_dt should only be provided if start_dt is provided.\")\n",
    "        end_dt_obj = datetime.strptime(end_dt, '%m/%d/%Y')\n",
    "    \n",
    "    \n",
    "    runs = get_runs_by_commit(start_dt=start_dt_obj.strftime('%m/%d/%Y'),\n",
    "                    end_dt=end_dt_obj.strftime('%m/%d/%Y'))\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often helpful to get runs in a batch in a date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/04/2023\"), lte(start_time, \"10/05/2023\"))\n",
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/03/2023\"), lte(start_time, \"10/06/2023\"))\n",
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/10/2023\"), lte(start_time, \"10/13/2023\"))\n"
     ]
    }
   ],
   "source": [
    "_runs1 = take(get_recent_runs(start_dt='10/4/2023', end_dt='10/5/2023'), 100)\n",
    "assert len(_runs1) >= 100\n",
    "\n",
    "_runs2 = take(get_recent_runs(start_dt='10/3/2023'), 100)\n",
    "assert len(_runs2)>= 100\n",
    "\n",
    "_runs3 = take(get_recent_runs(), 100)\n",
    "assert len(_runs3) >= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_recent_commit_tags(start_dt=None, end_dt=None, last_n_days=2, return_df=False):\n",
    "    \"Print a table of recent commit SHAs from Langsmith along with their counts that you can filter on\"\n",
    "    runs = L(get_recent_runs(start_dt=start_dt, end_dt=end_dt, last_n_days=last_n_days))\n",
    "    data = runs.map(lambda x: {'start_dt': x.start_time.strftime('%m/%d/%Y'),\n",
    "                        'commit': first([t.split('commit:')[-1] for t in x.tags if t.startswith('commit:')])\n",
    "                       }\n",
    "            )\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        agg = df.groupby(['start_dt']).value_counts().reset_index()\n",
    "        agg = agg.rename(columns={0: 'count'}).sort_values(by=['start_dt', 'count'], ascending=False)\n",
    "        if not return_df:\n",
    "            print(agg.to_markdown(index=False))\n",
    "        else:\n",
    "            return agg\n",
    "        \n",
    "    else:\n",
    "        print(f'No commits found for {start_dt} - {end_dt}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I like to tag my LangSmith runs with commit SHA (see `get_runs_by_commit`), I also want to see the most recent commit SHAs so I know what to query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/10/2023\"), lte(start_time, \"10/13/2023\"))\n",
      "| start_dt   | commit   |   count |\n",
      "|:-----------|:---------|--------:|\n",
      "| 10/12/2023 | f31454a6 |     269 |\n",
      "| 10/12/2023 | 8635b514 |     136 |\n",
      "| 10/10/2023 | 424c7c0d |    2511 |\n",
      "| 10/10/2023 | 2e627e02 |     572 |\n",
      "| 10/10/2023 | 6ec6605d |     571 |\n",
      "| 10/10/2023 | a1fdfd3e |     562 |\n",
      "| 10/10/2023 | 776a122d |     560 |\n",
      "| 10/10/2023 | 530cb929 |     554 |\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "get_recent_commit_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_recent_commit_tags` can also return a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching runs with this filter: and(eq(status, \"success\"), gte(start_time, \"10/10/2023\"), lte(start_time, \"10/13/2023\"))\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "_df = get_recent_commit_tags(return_df=True)\n",
    "assert _df.shape[0] >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Ways Of Getting Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also want to query runs by [feedback](https://docs.smith.langchain.com/evaluation/capturing-feedback), however there are many degrees of freedom with how you can implement feedback.  Furthermore, there are many ways you can utilize tags.  For these cases, we suggest using the `langsmith` client directly as [discussed earlier](#Background).  \n",
    "\n",
    "We will continue to update this library with additional recipes should we find other common patterns that are generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _ischatopenai(run): \n",
    "    if run.name != 'ChatOpenAI':\n",
    "        raise TypeError(f'Run: {run.id} is of type `{run.name}`, but can only parse `ChatOpenAI` runs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_params(run:langsmith.schemas.Run) -> dict:\n",
    "    \"Get important parameters from a run logged in LangSmith\"\n",
    "    if 'invocation_params' in run.extra:\n",
    "        p = run.extra['invocation_params']\n",
    "        return dict(param_model_name=p.get('model'),\n",
    "                    param_n=p.get('n'),\n",
    "                    param_top_p=p.get('top_p'),\n",
    "                    param_temp=p.get('temperature'),\n",
    "                    param_presence_penalty=p.get('presence_penalty'),\n",
    "                    param_freq_penalty=p.get('frequency_penalty')\n",
    "                   )\n",
    "    else: return {}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_model_name': 'gpt-3.5-turbo-0613',\n",
       " 'param_n': 1,\n",
       " 'param_top_p': 1,\n",
       " 'param_temp': 0,\n",
       " 'param_presence_penalty': 0,\n",
       " 'param_freq_penalty': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_run = client.read_run('8cd7deed-9547-4a07-ac01-55e9513ca1cd')\n",
    "get_params(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_functions(run:langsmith.schemas.Run) -> List[dict]:\n",
    "    \"Get function definitions from a LangSmith run.\"\n",
    "    if 'invocation_params' in run.extra:\n",
    "        p = run.extra['invocation_params']\n",
    "        return p.get('functions', [])\n",
    "    else: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact-finder\n",
      "contact-creator\n",
      "email-campaign-creator\n",
      "task-creator\n",
      "task-finder\n",
      "human-chat\n",
      "calculator\n",
      "knowledge-base\n"
     ]
    }
   ],
   "source": [
    "_funcs = get_functions(_run)\n",
    "for f in _funcs:\n",
    "    print(f['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "_funcs = get_functions(_run)\n",
    "assert _funcs[0]['name'] == 'contact-finder'\n",
    "assert len(_funcs) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_feedback(run:langsmith.schemas.Run) -> list:\n",
    "    \"Get feedback from a run if exists.\"\n",
    "    raw = L(client.list_feedback(run_ids=[run.id]))\n",
    "    return list(raw.map(lambda x: dict(key=x.key, \n",
    "                                       score=x.score, \n",
    "                                       value=x.value, \n",
    "                                       comment=x.comment, \n",
    "                                       correction=x.correction)\n",
    "                       )\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 'Empty Response',\n",
       "  'score': 0.0,\n",
       "  'value': None,\n",
       "  'comment': \"expected '' to have a length above 0 but got 0\",\n",
       "  'correction': None}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_feedback = get_feedback(client.read_run('7aba254d-3812-4050-85a5-ed64af50d2f1'))\n",
    "assert _feedback[0]['score'] == 0\n",
    "assert _feedback[0]['key'] == 'Empty Response'\n",
    "_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Runs To Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [experimental](03_experimental.ipynb) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
